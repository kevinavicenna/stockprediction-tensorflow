{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementation LSTM model for Forecasting\n",
    "### 'My Stock Forecast App' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yfinance as yf\n",
    "from datetime import date\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import metrics\n",
    "from math import sqrt\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.graph_objects as go"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DATA INGESTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input dari pengguna untuk simbol saham\n",
    "symbol = input(\"Input simbol saham (e.g 'BBRI.JK'): \")\n",
    "start_date = date(2019, 1, 1)\n",
    "end_date = date(2024, 3, 31)\n",
    "\n",
    "# Mengunduh data saham dari Yahoo Finance # Menambahkan kolom tanggal sebagai indeks\n",
    "data = yf.download(symbol, start=start_date, end=end_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.reset_index(inplace=True)\n",
    "\n",
    "# Input dari pengguna untuk fitur yang akan digunakan\n",
    "input_feat = input(\"Masukkan fitur yang akan digunakan ('Adj Close','Close'): \")\n",
    "\n",
    "data = data[[\"Date\", input_feat]]\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DATA PROCESSING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "scaled_data = scaler.fit_transform(data[input_feat].values.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pembagian data menjadi data training dan data testing\n",
    "train_size = int(len(scaled_data) * 0.8)\n",
    "train_data, test_data = scaled_data[:train_size, :], scaled_data[train_size:, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Persiapan Create Sequences LSTM\n",
    "def create_sequences(data, sequence_length):\n",
    "    sequences = []\n",
    "    target = []\n",
    "    for i in range(len(data) - sequence_length):\n",
    "        sequences.append(data[i:i+sequence_length])\n",
    "        target.append(data[i+sequence_length])\n",
    "    return np.array(sequences), np.array(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence_length = 10\n",
    "X_train, y_train = create_sequences(train_data, sequence_length)\n",
    "X_test, y_test = create_sequences(test_data, sequence_length)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(LSTM(units = 50, return_sequences = True, input_shape=(sequence_length, 1)))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(LSTM(units = 50, return_sequences = True))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(LSTM(units = 50))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Dense(units = 1))\n",
    "\n",
    "# model.compile(optimizer = 'adam', loss = 'mean_squared_error')\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cp3 = ModelCheckpoint('../model/model1_test/', save_best_only=True)\n",
    "# early_stopping = EarlyStopping(monitor='val_loss', patience=3, verbose=1, restore_best_weights=True)\n",
    "\n",
    "# # optimizer = Adam(learning_rate=0.001)\n",
    "# model.compile(loss='mean_squared_error', optimizer=Adam(learning_rate=0.001), metrics=['accuracy'])\n",
    "# model_final = model.fit(X_train, y_train, epochs=100, batch_size=32, verbose=2, callbacks=[cp3, early_stopping, tensorboard_callback], validation_data=(X_test, y_test))\n",
    "# %tensorboard --logdir logs/fit\n",
    "\n",
    "# Define callbacks\n",
    "cp3 = ModelCheckpoint('model/model1_test/', save_best_only=True)\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=3, verbose=1, restore_best_weights=True)\n",
    "tensorboard_callback = TensorBoard(log_dir=\"./logs\")\n",
    "\n",
    "# Compile the model\n",
    "optimizer = Adam(learning_rate=0.001)\n",
    "model.compile(loss='mean_squared_error', optimizer=optimizer, metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model_final = model.fit(X_train, y_train, epochs=100, batch_size=32, verbose=2, \n",
    "                         callbacks=[cp3, early_stopping], \n",
    "                         validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %tensorboard --logdir logs/fit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = model.evaluate(X_test, y_test)\n",
    "round_loss = [round(num, 5) for num in loss]\n",
    "print(\"Loss :\", round_loss)\n",
    "\n",
    "predict = model.predict(X_test)\n",
    "# print(predict)\n",
    "predict = scaler.inverse_transform(predict)\n",
    "# print(predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"-\"*15, \" Metric \",\"-\"*15)\n",
    "print('RMSE : ', round(sqrt(metrics.mean_squared_error(y_test, predict)), 5))\n",
    "print('MSE  : ', round(abs(metrics.mean_squared_error(y_test, predict)), 5))\n",
    "print('MAE  : ', round(metrics.mean_absolute_error(y_test, predict), 5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot loss\n",
    "sns.set(style=\"whitegrid\")\n",
    "\n",
    "sns.lineplot(x=range(len(model_final.history['loss'])), y=model_final.history['loss'], label='Training Loss')\n",
    "sns.lineplot(x=range(len(model_final.history['val_loss'])), y=model_final.history['val_loss'], label='Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training and Validation Loss Over Epochs')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "ts = int(time.time())\n",
    "file_path = f\"../lstm_stock/{ts}/\"\n",
    "model.save(filepath=file_path, save_format='tf')\n",
    "# model.save(\"../lstm_model3.keras\")\n",
    "print(\"Sucess saving model!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
